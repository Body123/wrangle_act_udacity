{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WeRateDogs Wrangling Efforts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first thing step in the data wrangling process is to gather all of the required data sets from different sources like reading a CSV file, using Python's requests library which was also used to download the data where tweepy was supposed to be used. Once the data was gathered it was time to assess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first step of assessment is visual assessment this is so important step. During this step, tidiness issues were identified. Issues such as distilling doggo, floofer pupper, and puppo values into a single variable, turning the three columnar observations found in the image classification table into variables  and separating replies and retweets into their own tables, .\n",
    "\n",
    "#### The second step of assessment includes programmatic assessment. During this step cleanliness issues were detected. For the archived twitter table, incorrect data types were appeared, columns should not contain HTML like what was in URL column, poor extraction of the numerator and denominator rating as well as it should be converted to a ratio to account for photos rated with more than one dog, non-names were identified - and None should be converted to np.nan. For image prediction, select columns for each observation where the confidence interval was the highest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Twitter Archive Table`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert dogtype values into a single column - dogtype Pandas apply method was used to execute a lambda function across doggo, floofer, pupper, and puppo columns to concatenate them into a single dogtionary variable.\n",
    "\n",
    "#### In fixing data types, timestamps converted to datetime objects, IDs to objects, dogtionary to category.\n",
    "\n",
    "#### To address the source column storing HTML, I mapped the values as there were only four of them and used pandas replace method.\n",
    "\n",
    "#### To improve name extraction, the name regex was rerun where name in [\"a\", \"None\", \"the\", \"an\"], and the first letter must be capital.\n",
    "\n",
    "#### Numerator and denominator columns were resolved by fixing the regex so that the fraction must end in 0. Then the rating ratio was calculated by dividing the numerator column by the denominator.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Image Prediction Table`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All IDs were converted to objects, and dates converted to datetime objects.\n",
    "#### The columns for each observational pass were converted into single variable columns containing data for each pass. This was done using Pandas melt method.\n",
    "#### Selected the pass which the highest in confidence for each ID - though it turns out that it happened to be p_1 for each row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Tweet JSON Tidiness`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Id types were set to object and dates were set to datetime objects.\n",
    "#### Selected only differing columns from archive table ['id', 'created_at', 'display_text_range', 'favorite_count', 'retweet_count'].\n",
    "#### display_text_range was converted to character_count using Panda's str method and the second index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
